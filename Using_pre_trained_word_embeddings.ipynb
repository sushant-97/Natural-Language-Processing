{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN6xcl+vXogqoau3pzmoeUD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sushant-97/keras_projects/blob/main/Using_pre_trained_word_embeddings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ],
      "metadata": {
        "id": "nX2_9irx1hv4"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DU01hube1NKm",
        "outputId": "d702d8f2-d4ff-44ea-9af8-fa89d7674398"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from http://www.cs.cmu.edu/afs/cs.cmu.edu/project/theo-20/www/data/news20.tar.gz\n",
            "17329808/17329808 [==============================] - 5s 0us/step\n"
          ]
        }
      ],
      "source": [
        "# Download dataset\n",
        "data_path = keras.utils.get_file(\n",
        "    \"news20.tar.gz\",\n",
        "    \"http://www.cs.cmu.edu/afs/cs.cmu.edu/project/theo-20/www/data/news20.tar.gz\",\n",
        "    untar=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LOguZ1Dn1aRJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pathlib\n",
        "\n",
        "data_dir = pathlib.Path(data_path).parent / \"20_newsgroup\"\n",
        "dirnames = os.listdir(data_dir)\n",
        "print(\"Number of directories:\", len(dirnames))\n",
        "print(\"Directory names:\", dirnames)\n",
        "\n",
        "fnames = os.listdir(data_dir / \"comp.graphics\")\n",
        "print(\"Number of files in comp.graphics:\", len(fnames))\n",
        "print(\"Some example filenames:\", fnames[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XEi-l2qb1pcv",
        "outputId": "59615740-bffd-4c63-e93d-0fa28514be90"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of directories: 20\n",
            "Directory names: ['sci.electronics', 'talk.politics.guns', 'comp.os.ms-windows.misc', 'sci.med', 'rec.sport.baseball', 'rec.sport.hockey', 'rec.autos', 'comp.sys.mac.hardware', 'rec.motorcycles', 'talk.religion.misc', 'talk.politics.mideast', 'comp.sys.ibm.pc.hardware', 'misc.forsale', 'soc.religion.christian', 'comp.graphics', 'alt.atheism', 'sci.crypt', 'talk.politics.misc', 'sci.space', 'comp.windows.x']\n",
            "Number of files in comp.graphics: 1000\n",
            "Some example filenames: ['38548', '39621', '38658', '38748', '38988']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Here's a example of what one file contains:\n",
        "print(open(data_dir / \"comp.graphics\" / \"38987\").read())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "96Z9HM2M1pZz",
        "outputId": "86032467-f65f-42d6-ba91-b64ef429a3c1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Newsgroups: comp.graphics\n",
            "Path: cantaloupe.srv.cs.cmu.edu!das-news.harvard.edu!noc.near.net!howland.reston.ans.net!agate!dog.ee.lbl.gov!network.ucsd.edu!usc!rpi!nason110.its.rpi.edu!mabusj\n",
            "From: mabusj@nason110.its.rpi.edu (Jasen M. Mabus)\n",
            "Subject: Looking for Brain in CAD\n",
            "Message-ID: <c285m+p@rpi.edu>\n",
            "Nntp-Posting-Host: nason110.its.rpi.edu\n",
            "Reply-To: mabusj@rpi.edu\n",
            "Organization: Rensselaer Polytechnic Institute, Troy, NY.\n",
            "Date: Thu, 29 Apr 1993 23:27:20 GMT\n",
            "Lines: 7\n",
            "\n",
            "Jasen Mabus\n",
            "RPI student\n",
            "\n",
            "\tI am looking for a hman brain in any CAD (.dxf,.cad,.iges,.cgm,etc.) or picture (.gif,.jpg,.ras,etc.) format for an animation demonstration. If any has or knows of a location please reply by e-mail to mabusj@rpi.edu.\n",
            "\n",
            "Thank you in advance,\n",
            "Jasen Mabus  \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Header lines are leaking the category, either explicitly - first line is category name or implicitly - via organization filled.\n",
        "Let's remove these"
      ],
      "metadata": {
        "id": "2iew3aL82_cS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "samples = []\n",
        "labels = []\n",
        "class_names = []\n",
        "class_index = 0\n",
        "\n",
        "for dirname in sorted(os.listdir(data_dir)):\n",
        "  class_names.append(dirname)\n",
        "  dirpath = data_dir/ dirname\n",
        "  fnames = os.listdir(dirpath)\n",
        "  print(\"Processing %s, %d files found\" % (dirname, len(fnames)))\n",
        "\n",
        "  for fname in fnames:\n",
        "    fpath = dirpath / fname\n",
        "    f = open(fpath, encoding = 'latin-1')\n",
        "    content = f.read()\n",
        "    lines = content.split(\"\\n\")\n",
        "    lines = lines[10:]\n",
        "    content = \"\\n\".join(lines)\n",
        "    samples.append(content)\n",
        "    labels.append(class_index)\n",
        "  class_index += 1\n",
        "\n",
        "print(\"Classes:\", class_names)\n",
        "print(\"Number of samples:\", len(samples))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q9El26VV1pW3",
        "outputId": "c6b60a07-46ea-442d-eab2-7f36e746684a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing alt.atheism, 1000 files found\n",
            "Processing comp.graphics, 1000 files found\n",
            "Processing comp.os.ms-windows.misc, 1000 files found\n",
            "Processing comp.sys.ibm.pc.hardware, 1000 files found\n",
            "Processing comp.sys.mac.hardware, 1000 files found\n",
            "Processing comp.windows.x, 1000 files found\n",
            "Processing misc.forsale, 1000 files found\n",
            "Processing rec.autos, 1000 files found\n",
            "Processing rec.motorcycles, 1000 files found\n",
            "Processing rec.sport.baseball, 1000 files found\n",
            "Processing rec.sport.hockey, 1000 files found\n",
            "Processing sci.crypt, 1000 files found\n",
            "Processing sci.electronics, 1000 files found\n",
            "Processing sci.med, 1000 files found\n",
            "Processing sci.space, 1000 files found\n",
            "Processing soc.religion.christian, 997 files found\n",
            "Processing talk.politics.guns, 1000 files found\n",
            "Processing talk.politics.mideast, 1000 files found\n",
            "Processing talk.politics.misc, 1000 files found\n",
            "Processing talk.religion.misc, 1000 files found\n",
            "Classes: ['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc']\n",
            "Number of samples: 19997\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This is a balanced classification problem"
      ],
      "metadata": {
        "id": "wnG4c4Ac1pUW"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Shuffle and split the data into training & validation sets"
      ],
      "metadata": {
        "id": "Wo2K-apE66D3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Shuffle the data\n",
        "seed = 1337\n",
        "\n",
        "rng = np.random.RandomState(seed)\n",
        "rng.shuffle(samples)\n",
        "rng = np.random.RandomState(seed)\n",
        "rng.shuffle(labels)\n",
        "\n",
        "# Training and validation split\n",
        "validation_split = 0.2\n",
        "num_vaidation_samples = int(validation_split * len(samples))\n",
        "train_samples = samples[ : -num_vaidation_samples]\n",
        "val_samples = samples[-num_vaidation_samples : ]\n",
        "\n",
        "train_labels = labels[ : -num_vaidation_samples]\n",
        "val_labels = labels[-num_vaidation_samples : ]"
      ],
      "metadata": {
        "id": "jAP1pcpW1pR6"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a vocabulary index"
      ],
      "metadata": {
        "id": "RDWdzV2x1pNM"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's use the TextVectorization to index the vocabulary found in the dataset. Later, we'll use the same layer instance to vectorize the samples.\n",
        "\n",
        "Our layer will only consider the top 20,000 words, and will truncate or pad sequences to be actually 200 tokens long."
      ],
      "metadata": {
        "id": "arcSrVVC8F4K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import TextVectorization\n",
        "\n",
        "vectorizer = TextVectorization(max_tokens = 20000, output_sequence_length = 200)\n",
        "text_ds = tf.data.Dataset.from_tensor_slices(train_samples).batch(128)\n",
        "vectorizer.adapt(text_ds)"
      ],
      "metadata": {
        "id": "7X3lJEIi1pKg"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Retriving computed vocabulary used\n",
        "vectorizer.get_vocabulary()[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H-lPhTP-1pHt",
        "outputId": "92fa7c1e-342c-41e4-a23b-d190c77d5521"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['', '[UNK]', 'the', 'to', 'of', 'a', 'and', 'in', 'is', 'i']"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Vectoring text sequence\n",
        "output = vectorizer([[\"the cat sat on the mat\"]])\n",
        "output.numpy()[0, :6]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5XrBTSHK1pEz",
        "outputId": "1d6110f3-b836-490d-d1dd-e7611373a5bd"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   2, 3554, 1793,   15,    2, 6340])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## 0 index - padding\n",
        "## 1 index - out of vocabulary tockens"
      ],
      "metadata": {
        "id": "XKh5hu-99As4"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dict mapping words to their indices:\n",
        "voc = vectorizer.get_vocabulary()\n",
        "word_index = dict(zip(voc, range(len(voc))))"
      ],
      "metadata": {
        "id": "PwvxYpxW9SKV"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test = [\"the\", \"cat\", \"sat\", \"on\", \"the\", \"mat\"]\n",
        "[word_index[w] for w in test]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gaBhHzXU9dsD",
        "outputId": "0507e88b-fa12-459c-ad32-dc7cfae4edd9"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2, 3554, 1793, 15, 2, 6340]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load pre-trained word embeddings\n",
        "Using GloVe Embeddings"
      ],
      "metadata": {
        "id": "-MS9KMdC9j-0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip -q glove.6B.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VJYjduZv9hsq",
        "outputId": "6bbdf969-b01c-45b7-fd30-502e0ac18e4c"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-10-21 14:33:40--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2022-10-21 14:33:40--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2022-10-21 14:33:41--  https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  5.02MB/s    in 2m 39s  \n",
            "\n",
            "2022-10-21 14:36:20 (5.17 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_glove_file = os.path.join(\n",
        "    os.path.expanduser(\"~\"), \"/content/glove.6B.100d.txt\"\n",
        ")\n",
        "\n",
        "embeddings_index = {}\n",
        "with open(path_to_glove_file) as f:\n",
        "    for line in f:\n",
        "        word, coefs = line.split(maxsplit=1)\n",
        "        coefs = np.fromstring(coefs, \"f\", sep=\" \")\n",
        "        embeddings_index[word] = coefs\n",
        "\n",
        "print(\"Found %s word vectors.\" % len(embeddings_index))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IHPJpbvk9sTg",
        "outputId": "f49d4041-a409-41e7-857d-831b76a8000c"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 400000 word vectors.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Embedding matrix that can be used in Keras Embedding layer\n",
        "num_tokens = len(voc) + 2\n",
        "embedding_dim = 100\n",
        "hits = 0\n",
        "misses = 0\n",
        "\n",
        "# Prepare embedding matrix\n",
        "embedding_matrix = np.zeros((num_tokens, embedding_dim))\n",
        "for word, i in word_index.items():\n",
        "  embedding_vector = embeddings_index.get(word)\n",
        "  if embedding_vector is not None:\n",
        "    # Words not found in embedding index will be all-zeros.\n",
        "    # This includes the representation for \"padding\" and \"OOV\"\n",
        "    embedding_matrix[i] = embedding_vector\n",
        "    hits += 1\n",
        "  else:\n",
        "    misses += 1\n",
        "\n",
        "print(\"Converted %d words (%d misses)\" % (hits, misses))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f4WbXA9p-lBq",
        "outputId": "70cede6f-f1bb-4357-e556-944d9ec3d99e"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converted 18013 words (1987 misses)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*  Loading pre-trained word embeddings matrix into an Embedding layer\n",
        "*   Keeping trainable = False, so as to keep the embeddings fixed\n",
        "\n"
      ],
      "metadata": {
        "id": "4BdajRvfAWQK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Embedding\n",
        "\n",
        "embedding_layer = Embedding(\n",
        "    num_tokens,\n",
        "    embedding_dim,\n",
        "    embeddings_initializer = keras.initializers.Constant(embedding_matrix),\n",
        "    trainable = False,\n",
        ")"
      ],
      "metadata": {
        "id": "xlqVLugdAIDD"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build the model"
      ],
      "metadata": {
        "id": "cFoE1LE5BEk9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers\n",
        "\n",
        "int_sequences_input = keras.Input(shape = (None, ), dtype = 'int64')\n",
        "embedded_sequences = embedding_layer(int_sequences_input)\n",
        "\n",
        "x = layers.Conv1D(128, 5, activation=\"relu\")(embedded_sequences)\n",
        "x = layers.MaxPooling1D(5)(x)\n",
        "x = layers.Conv1D(128, 5, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling1D(5)(x)\n",
        "x = layers.Conv1D(128, 5, activation=\"relu\")(x)\n",
        "x = layers.GlobalMaxPooling1D()(x)\n",
        "x = layers.Dense(128, activation=\"relu\")(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "\n",
        "preds = layers.Dense(len(class_names), activation=\"softmax\")(x)\n",
        "model = keras.Model(int_sequences_input, preds)\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NsJ-ELTEBBRq",
        "outputId": "603de29f-8433-47ce-9f22-997704d1f135"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, None)]            0         \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, None, 100)         2000200   \n",
            "                                                                 \n",
            " conv1d (Conv1D)             (None, None, 128)         64128     \n",
            "                                                                 \n",
            " max_pooling1d (MaxPooling1D  (None, None, 128)        0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, None, 128)         82048     \n",
            "                                                                 \n",
            " max_pooling1d_1 (MaxPooling  (None, None, 128)        0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " conv1d_2 (Conv1D)           (None, None, 128)         82048     \n",
            "                                                                 \n",
            " global_max_pooling1d (Globa  (None, 128)              0         \n",
            " lMaxPooling1D)                                                  \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               16512     \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 128)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 20)                2580      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,247,516\n",
            "Trainable params: 247,316\n",
            "Non-trainable params: 2,000,200\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train the model"
      ],
      "metadata": {
        "id": "7bftXsKbBq2K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = vectorizer(np.array([[s] for s in train_samples])).numpy()\n",
        "x_val = vectorizer(np.array([[s] for s in val_samples])).numpy()\n",
        "\n",
        "y_train = np.array(train_labels)\n",
        "y_val = np.array(val_labels)"
      ],
      "metadata": {
        "id": "HhYy-rTBBnfX"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    loss=\"sparse_categorical_crossentropy\", optimizer=\"rmsprop\", metrics=[\"acc\"]\n",
        ")\n",
        "model.fit(x_train, y_train, batch_size=128, epochs=20, validation_data=(x_val, y_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-i-AHn_fCh8Q",
        "outputId": "38b2236c-f459-4d2e-d89c-d75460d0491f"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "125/125 [==============================] - 32s 13ms/step - loss: 2.6684 - acc: 0.1436 - val_loss: 2.0456 - val_acc: 0.2966\n",
            "Epoch 2/20\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 1.9373 - acc: 0.3312 - val_loss: 1.6134 - val_acc: 0.4424\n",
            "Epoch 3/20\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 1.5242 - acc: 0.4751 - val_loss: 1.3002 - val_acc: 0.5571\n",
            "Epoch 4/20\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 1.2715 - acc: 0.5598 - val_loss: 1.1422 - val_acc: 0.6132\n",
            "Epoch 5/20\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 1.0930 - acc: 0.6189 - val_loss: 1.0985 - val_acc: 0.6239\n",
            "Epoch 6/20\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.9694 - acc: 0.6581 - val_loss: 1.0678 - val_acc: 0.6329\n",
            "Epoch 7/20\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.8674 - acc: 0.6948 - val_loss: 1.0928 - val_acc: 0.6399\n",
            "Epoch 8/20\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.7594 - acc: 0.7337 - val_loss: 0.9841 - val_acc: 0.6739\n",
            "Epoch 9/20\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.6646 - acc: 0.7638 - val_loss: 1.0261 - val_acc: 0.6674\n",
            "Epoch 10/20\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.5870 - acc: 0.7895 - val_loss: 1.0272 - val_acc: 0.6814\n",
            "Epoch 11/20\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.5041 - acc: 0.8185 - val_loss: 1.1682 - val_acc: 0.6537\n",
            "Epoch 12/20\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.4495 - acc: 0.8392 - val_loss: 1.0718 - val_acc: 0.6937\n",
            "Epoch 13/20\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.3946 - acc: 0.8627 - val_loss: 1.3304 - val_acc: 0.6764\n",
            "Epoch 14/20\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.3423 - acc: 0.8791 - val_loss: 1.1832 - val_acc: 0.6727\n",
            "Epoch 15/20\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.3100 - acc: 0.8945 - val_loss: 1.2349 - val_acc: 0.6967\n",
            "Epoch 16/20\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.2725 - acc: 0.9092 - val_loss: 1.3304 - val_acc: 0.6784\n",
            "Epoch 17/20\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.2441 - acc: 0.9186 - val_loss: 1.3418 - val_acc: 0.7037\n",
            "Epoch 18/20\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.2232 - acc: 0.9254 - val_loss: 1.5313 - val_acc: 0.6874\n",
            "Epoch 19/20\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.2055 - acc: 0.9312 - val_loss: 1.6046 - val_acc: 0.6677\n",
            "Epoch 20/20\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1870 - acc: 0.9367 - val_loss: 1.5426 - val_acc: 0.7054\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f004d163c10>"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's export a Model object that takes as input a string of arbitrary length, rather than a sequence of indices.\n",
        "It would make model much more portable, since we wouldn't have to worry about the input processing pipeline"
      ],
      "metadata": {
        "id": "HQmNz8mFC9GP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "string_input = keras.Input(shape = (1,), dtype = 'string')\n",
        "x = vectorizer(string_input)\n",
        "preds = model(x)\n",
        "\n",
        "end2end_model = keras.Model(string_input, preds)\n",
        "\n",
        "probabilities = end2end_model.predict([[\"this message is about computer graphics and 3D modeling\"]])\n",
        "\n",
        "class_names[np.argmax(probabilities[0])]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "2un91OsZCn9W",
        "outputId": "bba72039-ae74-408b-84c5-1c2b2d7d3204"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 265ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'comp.graphics'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "e2PsRJpCDs6b"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}